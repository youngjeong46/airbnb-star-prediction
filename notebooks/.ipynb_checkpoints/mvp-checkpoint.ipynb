{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting a 5-Star Airbnb Ratings\n",
    "\n",
    "Young Jeong\n",
    "\n",
    "In this project, I use different classification algorithms to generate a model that best predicts whether an Airbnb listing has a 5-star ratings or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Abstract\" data-toc-modified-id=\"Abstract-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Abstract</a></span></li><li><span><a href=\"#Obtain-the-Data\" data-toc-modified-id=\"Obtain-the-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Obtain the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Airbnb-Data\" data-toc-modified-id=\"Airbnb-Data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Airbnb Data</a></span></li></ul></li><li><span><a href=\"#Scrub-the-Data\" data-toc-modified-id=\"Scrub-the-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Scrub the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Adding-useful-features-1:-Walkscore\" data-toc-modified-id=\"Adding-useful-features-1:-Walkscore-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Adding useful features 1: Walkscore</a></span></li></ul></li><li><span><a href=\"#Explore-the-Data\" data-toc-modified-id=\"Explore-the-Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Explore the Data</a></span></li><li><span><a href=\"#Model-the-Data\" data-toc-modified-id=\"Model-the-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model the Data</a></span></li><li><span><a href=\"#Interpret-the-Model\" data-toc-modified-id=\"Interpret-the-Model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Interpret the Model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "In the past few years, short-term rental business has become a vital part of the hospitality business, and as a result, Airbnb has grown into an international giant in the space. As a previous Airbnb host, I often struggle with keeping the highest of qualities for my guests. Perception is a big thing, and I know I was fighting to keep my ratings at a 5-star level. Why? Because Airbnb grants a special designation called SuperHost that will lead to a higher visibility, bonus perks and higher income (Airbnb states increase in income of 22% or up to $2250 a month).\n",
    "\n",
    "This leads to my main question of the topic: Is there some correlation between certain information or features about a listing and its rating? Can I build a model that can 1. Tell me strong indicators of a 5-star ratings and 2. Therefore correctly predict a listings ratings (whether it is a 5-star or not?) I believe this can help two groups of people and they are:\n",
    "\n",
    "1. Potential hosts that wants to curate their listings to attract and hopefully receive 5-star ratings, and\n",
    "2. Current hosts that want to move towards the 5-star ratings in their first steps of becoming a SuperHost.\n",
    "\n",
    "So here comes my journey in generating that model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the Data\n",
    "\n",
    "### Airbnb Data\n",
    "\n",
    "The Main data source was from insideairbnb.com, a non-profit website that scrapes Airbnb data for visualization purposes. It's nicely categorized into different major cities, one of which is Seattle. I decided to look at the latest scraped data of the listings in Seattle for this project.\n",
    "\n",
    "The file is in a CSV format and has about 8400 listings and various information about them in columns. Please see \n",
    "`references/data_dictionary` for more details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrub the Data\n",
    "\n",
    "There are lots of features in the scraped Airbnb flatfile; 106 of them to be exact. Taking a look at all of them gives some insight as to which features and usable and not.\n",
    "\n",
    "After carefully looking at them, I've determined these to be useful:\n",
    "\n",
    "- 'host_since' - How long a host has been a host on Airbnb\n",
    "- 'host_response_time' - How long it takes for the host to respond back to potential guests or guests\n",
    "- 'host_response_rate' - How much the host responds to messages (rate of response vs total messages)\n",
    "- 'host_total_listings_count' - How many listings hosts own \n",
    "- 'host_verifications' - How many ways has Airbnb verified hosts (IDs, phone numbers etc.)\n",
    "- 'host_has_profile_pic', - Does Host have profile pictures\n",
    "- 'host_identity_verified' - is host's identity verified by Airbnb\n",
    "- 'neighbourhood_cleansed' - Neighbourhood the listing is located in\n",
    "- 'zipcode' - Zipcode of the listing\n",
    "- 'latitude' - latitude of the listing\n",
    "- 'longitude' - longitude of the listing\n",
    "- 'room_type' - Type of room (Entire house or a room in a house)\n",
    "- 'bathrooms' - # of Bathrooms \n",
    "- 'bedrooms' - # of bedrooms\n",
    "- 'beds' - # of beds\n",
    "- 'bed_type' - Types of beds provided\n",
    "- 'amenities' - Amenities provided\n",
    "- 'price' - Price of the listing (per night)\n",
    "- 'security_deposit' - Security Deposit (if required)\n",
    "- 'cleaning_fee' - Cleaning Fee (if required)\n",
    "- 'extra_people' - How many extra people are allowed\n",
    "- 'minimum_nights' - Minimum nights required per reservation\n",
    "- 'calendar_updated' - How often the listing's calendar is updated\n",
    "- 'availability_30' - How many days available within the next 30 days\n",
    "- 'availability_90' - How many days available within the next 90 days\n",
    "- 'cancellation_policy' - Cancellation policy\n",
    "- 'reviews_per_month' - How many reviews are received per month\n",
    "- 'review_scores_rating' - Ratings (our target variable)\n",
    "\n",
    "### Adding useful features 1: Walkscore\n",
    "\n",
    "Using the latitude and longitude features, I first decided to use google's geocode API to map out the exact street address. This was necessary step because in order to use the Walkscore's API, street address was required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/features/build_features.py\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import googlemaps\n",
    "from psycopg2 import connect\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def dataset_sql(directory, filename):\n",
    "    \n",
    "    df = pd.read_csv(directory+filename,delimiter=',',low_memory=False)\n",
    "    \n",
    "    params = {\n",
    "        'host': '127.0.0.1',\n",
    "        'user': 'youngjeong',\n",
    "        'port': 5432\n",
    "    }\n",
    "    \n",
    "    connection = connect(**params, dbname='listings')\n",
    "    connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    connection.cursor().execute('CREATE DATABASE listings;')\n",
    "    connection_string = f'postgres://youngjeong:{params[\"host\"]}@{params[\"host\"]}:{params[\"port\"]}/listings'\n",
    "    engine = create_engine(connection_string)\n",
    "    df.to_sql('listings', engine, index=False)\n",
    "\n",
    "# Retrieves street address from Google using Geocode API\n",
    "def retrieve_address():\n",
    "    cursor.execute(\"SELECT latitude, longitude FROM listings\")\n",
    "    latlong = cursor.fetchall()\n",
    "    gmaps = googlemaps.Client(key='AIzaSyAg7a4wxLj2jhH1dHkzxPolTXIzItbz5x0')\n",
    "    \n",
    "    add_list=[]\n",
    "    \n",
    "    for i in range(latlong.shape[0]):\n",
    "        lat = latlong[i][0]\n",
    "        long = latlong[i][1]\n",
    "        address = gmaps.reverse_geocode((round(lat,6), round(long,6)))\n",
    "        add_list.append(address[0]['formatted_address'])\n",
    "    \n",
    "    return add_list\n",
    "\n",
    "def get_walkscore_url(address, city, zip_code, lat, lon):\n",
    "    \"\"\"\n",
    "    Construct url for Walkscore api call\n",
    "    Input: address, city, and zip_code as strings; lat/lon coords as float\n",
    "    Output: prepared url to request walkscore for address\n",
    "    \"\"\"\n",
    "    api_key = '466d1cb991e8a99345b049d505c6a4a7'\n",
    "    base_url = 'http://api.walkscore.com/score?format=json'\n",
    "    mid_url = 'transit=1&bike=1'\n",
    "    address = 'address=' + '%'.join(address.split())\n",
    "    address = '%20'.join([address, city, 'WA', zip_code])\n",
    "    lat = f'lat={lat}'\n",
    "    lon = f'lon={lon}'\n",
    "    api_key = f'wsapikey={api_key}'\n",
    "    url = '&'.join([base_url, address, lat, lon, mid_url, api_key])\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_walkscores(row):\n",
    "    \"\"\"\n",
    "    Makes api call to Walkscore and extracts bike, walk, and transit scores\n",
    "    Input: dataframe row containing required fields\n",
    "    Output: list containing bike, walk, and transit scores (or nan, if failure)\n",
    "    \"\"\"\n",
    "    fields = ['address1', 'city', 'zip_code', 'latitude', 'longitude']\n",
    "    address, city, zip_code, lat, lon = row[fields]\n",
    "    url = get_walkscore_url(address, city, zip_code, lat, lon)\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        response = json.loads(r.text)\n",
    "\n",
    "        bike_score = response['bike']['score']\n",
    "        walk_score = response['walkscore']\n",
    "        transit_score = response['transit']['score']\n",
    "    except:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    return [bike_score, walk_score, transit_score]\n",
    "    \n",
    "    \n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/raw, cleans them,\n",
    "    and converts the data into a design matrix that is ready for modeling.\n",
    "    \"\"\"\n",
    "    dataset_sql('../data/raw/', 'listings.csv')\n",
    "    add_list = retrieve_address()\n",
    "    # clean_dataset_2('data/raw', filename)\n",
    "    # save_cleaned_data_1('data/interim', filename)\n",
    "    # save_cleaned_data_2('data/interim', filename)\n",
    "    # build_features()\n",
    "    # save_features('data/processed')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before moving on to exploratory analysis, write down some notes about challenges encountered while working with this data that might be helpful for anyone else (including yourself) who may work through this later on.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "\n",
    "*Before you start exploring the data, write out your thought process about what you're looking for and what you expect to find. Take a minute to confirm that your plan actually makes sense.*\n",
    "\n",
    "*Calculate summary statistics and plot some charts to give you an idea what types of useful relationships might be in your dataset. Use these insights to go back and download additional data or engineer new features if necessary. Not now though... remember we're still just trying to finish the MVP!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/visualization/visualize.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed')\n",
    "    # describe_features(data, 'reports/')\n",
    "    # generate_charts(data, 'reports/figures/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What did you learn? What relationships do you think will be most helpful as you build your model?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model the Data\n",
    "\n",
    "*Describe the algorithm or algorithms that you plan to use to train with your data. How do these algorithms work? Why are they good choices for this data and problem space?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/train_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed/')\n",
    "    # train, test = train_test_split(data)\n",
    "    # save_train_test(train, test, 'data/processed/')\n",
    "    # model = build_model()\n",
    "    # model.fit(train)\n",
    "    # save_model(model, 'models/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/predict_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # test_X, test_y = load_test_data('data/processed')\n",
    "    # trained_model = load_model('models/')\n",
    "    # predictions = trained_model.predict(test_X)\n",
    "    # metrics = evaluate(test_y, predictions)\n",
    "    # save_metrics('reports/')\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write down any thoughts you may have about working with these algorithms on this data. What other ideas do you want to try out as you iterate on this pipeline?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret the Model\n",
    "\n",
    "_Write up the things you learned, and how well your model performed. Be sure address the model's strengths and weaknesses. What types of data does it handle well? What types of observations tend to give it a hard time? What future work would you or someone reading this might want to do, building on the lessons learned and tools developed in this project?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "317.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
